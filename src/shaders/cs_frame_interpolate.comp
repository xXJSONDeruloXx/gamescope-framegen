#version 450

#extension GL_GOOGLE_include_directive : require
#extension GL_EXT_scalar_block_layout : require

#include "descriptor_set.h"
#include "frame_interpolation.h"

layout(
  local_size_x = 8,
  local_size_y = 8,
  local_size_z = 1) in;

// Additional bindings for frame interpolation
layout(set = 0, binding = 16) uniform sampler2D s_currentFrame;
layout(set = 0, binding = 17) uniform sampler2D s_previousFrame;
layout(set = 0, binding = 18, rgba8) uniform writeonly image2D dst_interpolated;

// Push constants for frame interpolation
layout(push_constant, scalar) uniform FrameInterpolationPushData {
    float mixFactor;  // How much to blend between frames (0.5 = halfway)
    uint enableOcclusion; // Whether to enable occlusion detection
    float motionSensitivity; // Adjusts the motion detection threshold
    uint debugMode; // 0 = normal, 1 = show motion vectors, 2 = show occlusion
};

// Helper function to visualize motion vectors
vec4 visualizeMotionVectors(vec2 motion) {
    // Normalize and scale for visibility
    vec2 normalizedMotion = normalize(motion) * 0.5 + 0.5;
    // Use x/y components as R/G channels, intensity as B
    return vec4(normalizedMotion.x, normalizedMotion.y, length(motion) * 5.0, 1.0);
}

void main() {
    uvec2 coord = uvec2(gl_GlobalInvocationID.x, gl_GlobalInvocationID.y);
    uvec2 outSize = imageSize(dst_interpolated);

    if (coord.x >= outSize.x || coord.y >= outSize.y)
        return;

    vec2 uv = vec2(coord) / vec2(outSize);
    
    // Perform frame interpolation
    vec4 outputColor;
    
    // Calculate search radius based on potential movement speed
    float searchRadius = 0.03 * motionSensitivity;
    
    // Estimate motion vector from current to previous frame
    vec2 motionVector = estimateMotion(s_currentFrame, s_previousFrame, uv, searchRadius);
    
    if (debugMode == 1) {
        // Visualize motion vectors
        outputColor = visualizeMotionVectors(motionVector);
    } else {
        // Skip interpolation for small movements (reduces artifacts in static regions)
        float motionMagnitude = length(motionVector);
        if (motionMagnitude < MOTION_THRESHOLD * motionSensitivity) {
            outputColor = texture(s_currentFrame, uv);
        } else {
            // Sample from both frames with motion offset
            vec4 current = texture(s_currentFrame, uv);
            vec4 previous = texture(s_previousFrame, uv + motionVector * mixFactor);
            
            float finalMixFactor = mixFactor;
            
            if (enableOcclusion != 0) {
                // Detect occlusions (where motion estimation likely failed)
                vec4 directPrevious = texture(s_previousFrame, uv);
                float colorDiff = length(current.rgb - directPrevious.rgb);
                float occlusionFactor = smoothstep(0.1, 0.3, colorDiff);
                
                if (debugMode == 2) {
                    // Visualize occlusion
                    outputColor = vec4(occlusionFactor, 0.0, 0.0, 1.0);
                    imageStore(dst_interpolated, ivec2(coord), outputColor);
                    return;
                }
                
                // Reduce interpolation weight in occlusion areas
                finalMixFactor = mix(mixFactor, 0.0, occlusionFactor);
            }
            
            // Blend between frames
            outputColor = mix(current, previous, finalMixFactor);
        }
    }
    
    // Convert from linear to the appropriate output colorspace
    outputColor.rgb = encodeOutputColor(outputColor.rgb);
    
    // Write the result
    imageStore(dst_interpolated, ivec2(coord), outputColor);
}